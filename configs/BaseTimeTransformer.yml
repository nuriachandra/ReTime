# Configuration file for training BaseTimeTransformer model

# Data configuration
data_path: "data/synthetic_data/time_series.npy"  # Path to the time series data
normalize_data: true               # Whether to normalize the data
train_ratio: 0.7                   # Ratio of data for training
val_ratio: 0.15                    # Ratio of data for validation
# test_ratio is 1 - train_ratio - val_ratio

# Model configuration
block_size: 512                    # Sequence length (input window size)
n_layer: 6                         # Number of transformer layers
n_head: 8                          # Number of attention heads
n_embd: 512                        # Embedding dimension
h: 24                              # Horizon length (prediction steps)
dropout: 0.1                       # Dropout rate
bias: true                         # Whether to use bias in Linear layers

# Training configuration
output_dir: "output"               # Directory to save outputs
seed: 42                           # Random seed for reproducibility
use_gpu: true                      # Whether to use GPU for training
batch_size: 64                     # Batch size
epochs: 100                        # Maximum number of epochs
learning_rate: 0.0001              # Learning rate
weight_decay: 0.0001               # Weight decay for regularization
gradient_clip: 1.0                 # Maximum gradient norm
patience: 15                       # Early stopping patience
