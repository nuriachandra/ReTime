{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d303e8ad",
   "metadata": {},
   "source": [
    "Gather data from\n",
    "https://huggingface.co/datasets/autogluon/chronos_datasets\n",
    "\n",
    "All data is in the 'train' split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9db5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"autogluon/chronos_datasets\", \"monash_covid_deaths\", split=\"train\")\n",
    "ds.set_format(\"numpy\")  # sequences returned as numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d86e7a",
   "metadata": {},
   "source": [
    "Each time series has an 'id', and array of timestamps 'timestamp', and an array of values 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1a194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: T000000\n",
      "timestamp: of shape (212,) contains entries like: 2020-01-22T00:00:00.000\n",
      "target of shape (212,) contains entries like 0.0\n"
     ]
    }
   ],
   "source": [
    "example_timeseries = ds[0]\n",
    "print(\"id:\", example_timeseries[\"id\"])\n",
    "print(\n",
    "    f\"timestamp: of shape {example_timeseries['timestamp'].shape} contains entries like:\",\n",
    "    example_timeseries[\"timestamp\"][0],\n",
    ")\n",
    "print(f\"target of shape {example_timeseries['target'].shape} contains entries like\", example_timeseries[\"target\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7a2ba",
   "metadata": {},
   "source": [
    "Interestingly, the 'target' array is not the predition targets for the models. Instead 'target' contains all of the values of the timeseries. \n",
    "\n",
    "The prediction length $H$ used for each of the datasets by the Chronos paper is described on page 31 of https://arxiv.org/pdf/2403.07815\n",
    "\n",
    "$H$ is dataset-specific, and the last $H$ of each time series was used for the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efa0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  timestamp  target\n",
      "0    T000000 2020-01-22     0.0\n",
      "0    T000000 2020-01-23     0.0\n",
      "0    T000000 2020-01-24     0.0\n",
      "0    T000000 2020-01-25     0.0\n",
      "0    T000000 2020-01-26     0.0\n",
      "..       ...        ...     ...\n",
      "265  T000265 2020-08-16   132.0\n",
      "265  T000265 2020-08-17   135.0\n",
      "265  T000265 2020-08-18   141.0\n",
      "265  T000265 2020-08-19   150.0\n",
      "265  T000265 2020-08-20   151.0\n",
      "\n",
      "[56392 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# We can convert data in such format to a long format data frame\n",
    "def to_pandas(ds: datasets.Dataset) -> \"pd.DataFrame\":\n",
    "    \"\"\"Convert dataset to long data frame format.\"\"\"\n",
    "    sequence_columns = [col for col in ds.features if isinstance(ds.features[col], datasets.Sequence)]\n",
    "    return ds.to_pandas().explode(sequence_columns).infer_objects()\n",
    "\n",
    "\n",
    "print(to_pandas(ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
